A Spanish court has ruled a former Facebook moderator’s mental health was damaged by his work reviewing graphic content such as beheadings, in a case that could have implications for how social media firms work with moderators.
The Barcelona court, upholding a decision by Spain’s social security agency, said the psychiatric treatment the subcontracted moderator required was due to work-related issues, meaning he is entitled to extra compensation for sick leave.
The moderator was employed between 2018 and 2020 by CCC Barcelona Digital Services, part of Telus International, which is one of Facebook owner Meta’s outsourced providers.
Telus said it was disappointed by the ruling and would appeal.
A Meta spokesperson declined to comment as the company “is not party to the case in question.”
It is the first time in Spain that a court has recognized a content moderator’s sick leave was caused by their job, said Francesc Feliu, the worker’s lawyer who is also representing around 20 other former and current content moderators at CCC on similar legal grounds.
The former worker had to watch content including “self-mutilations, beheadings of civilians murdered by terrorist groups, torture inflicted on people, suicides,” the court said.
CCC filed a lawsuit in 2022 seeking to overturn the social security agency’s decision that the moderator’s mental health condition was the result of his work.
In his Jan. 12 ruling, seen by Reuters, Judge Jesus Fuertes rejected CCC’s claim.
“The worker has been suffering a situation of great emotional and psychological impact in his job,” he wrote, adding that the leave granted in 2019 was “exclusively and undoubtedly” caused by his work.
The worker’s incapacity to work was caused by severe anxiety including panic attacks, isolation, dysphagia and thanatophobia, the ruling said.
Martha Dark, director at London-based tech-justice advocacy group Foxglove, said the court was “100% right to recognize the work of keeping Facebook safe causes mental health illness.”
“Meta needs to compensate this brave ex-moderator for the harm they’ve suffered – but that’s only half the battle,” she said. “They must also be forced to provide ongoing real mental health care and safe workplaces for the tens of thousands of workers doing this work around the world.”
Dark, whose group was not involved in this case, but has helped organize a content moderators’ campaign over their work conditions, urged governments to introduce regulation to ensure social media platforms are safe for both for users and workers.
In 2020, Facebook agreed a settlement with U.S. content moderators suffering mental health issues. Last year, a moderator in Germany was put on paid leave pending an internal investigation after he called for an improvement in working conditions.
(Reporting by Joan Faus and Catarina Demony; editing by Charlie Devereux, Mark Potter and Alison Williams)

Topics
Legislation
