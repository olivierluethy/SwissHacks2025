EU industry chief Thierry Breton will meet Meta Platforms Chief Executive Mark Zuckerberg on June 23 and demand that he act immediately to tackle content targeting children, as Meta’s voluntary child protection code seemed not to be working.
Social media platforms such as Meta’s Instagram, ByteDance’s TikTok, Snap’s Snapchat and Alphabet’s YouTube have stirred concerns among regulators and users over content targeted at young children.
“Meta’s voluntary code on child protection seems not to work,” Breton said in a Twitter post.
“Mark Zuckerberg must now explain and take immediate action,” he said, confirming what an EU official had earlier told Reuters. “I will discuss with him at Meta‘s HQ in Menlo Park (California) on 23 June.”
A spokesperson for Meta said it has strict policies and technology to prevent predators from finding or interacting with teenagers on its apps.
She said Meta teams had dismantled 27 abusive networks between 2020 and 2022 while in January this year it had disabled more than 490,000 accounts for violating its child safety policies.
“We’re continuously exploring ways to actively defend against this behavior, and we set up an internal task force to investigate these claims and immediately address them.”
Breton said Meta would also have to demonstrate the measures it plans to take to comply with European Union online content rules known as the Digital Services Act (DSA) after Aug. 25 or face heavy sanctions.
The DSA bans certain types of targeted advertisements on online platforms such as those meant for children or when they use special categories of personal data, such as ethnicity, political views and sexual orientation.
DSA fines for breaches can go to as high as 6% of a company’s global turnover.

Topics
Europe
